import { Client, GatewayIntentBits, AttachmentBuilder } from "discord.js";
import {
  joinVoiceChannel,
  getVoiceConnection,
  createAudioPlayer,
  createAudioResource,
  AudioPlayerStatus,
} from "@discordjs/voice";
import OpenAI from "openai";
import dotenv from "dotenv";
import { pipeline } from "stream";
import prism from "prism-media";
import fs from "fs-extra";
import path from "path";
import { fileURLToPath } from "url";
import ffmpeg from "fluent-ffmpeg";
import screenshot from "screenshot-desktop";
import webcam from "node-webcam";
import { execSync } from "child_process";
import http from "http";

dotenv.config();

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const client = new Client({
  intents: [
    GatewayIntentBits.Guilds,
    GatewayIntentBits.GuildMessages,
    GatewayIntentBits.MessageContent,
    GatewayIntentBits.GuildVoiceStates,
  ],
});

// Initialiser OpenAI pour toutes les fonctionnalit√©s
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY || "" });

if (!process.env.OPENAI_API_KEY) {
  console.warn("‚ö†Ô∏è OPENAI_API_KEY non d√©fini. Le bot ne pourra pas fonctionner correctement.");
}

// Configuration de la voix TTS
// Options disponibles : "alloy" (neutre), "echo" (masculine), "fable" (masculine), 
//                       "onyx" (masculine profonde), "nova" (f√©minine), "shimmer" (f√©minine douce)
const TTS_VOICE = process.env.JARVIS_TTS_VOICE || "echo";  // Voix masculine par d√©faut (comme Jarvis)
const TTS_SPEED = parseFloat(process.env.JARVIS_TTS_SPEED || "0.95");  // Vitesse de la voix

// Styles selon l'utilisateur
const userStyles = {
  "729630625518190603": "R√©pond de fa√ßon sarcastique.",
  "414754147556917258": "R√©pond avec respect comme un roi.",
};

client.once("clientReady", () => {
  console.log(`ü§ñ Connect√© en tant que ${client.user.tag}`);
});

// Garder la compatibilit√© avec l'ancien √©v√©nement
client.once("ready", () => {
  console.log(`ü§ñ Connect√© en tant que ${client.user.tag}`);
});

// Fonction pour transcrire l'audio avec OpenAI Whisper
async function transcribeAudioWithOpenAI(audioBuffer) {
  try {
    // Sauvegarder temporairement pour conversion si n√©cessaire
    const tempPath = path.join(__dirname, `temp_transcribe_${Date.now()}.pcm`);
    fs.writeFileSync(tempPath, audioBuffer);
    
    // Convertir en format MP3 pour OpenAI Whisper (format recommand√©)
    const mp3Path = tempPath.replace(".pcm", ".mp3");
    
    return new Promise((resolve, reject) => {
      ffmpeg(tempPath)
        .toFormat("mp3")
        .audioFrequency(16000)
        .audioChannels(1)
        .audioCodec("libmp3lame")
        .audioBitrate(64)
        .save(mp3Path)
        .on("end", async () => {
          try {
            // Lire le fichier MP3
            const audioFile = fs.createReadStream(mp3Path);
            
            // Utiliser OpenAI Whisper pour la transcription audio
            const transcription = await openai.audio.transcriptions.create({
              file: audioFile,
              model: "whisper-1",
              language: "fr",
              response_format: "text"
            });
            
            const transcribedText = typeof transcription === 'string' ? transcription.trim() : transcription.text?.trim() || "";
            
            // Nettoyer les fichiers temporaires
            if (fs.existsSync(tempPath)) fs.removeSync(tempPath);
            if (fs.existsSync(mp3Path)) fs.removeSync(mp3Path);
            
            resolve(transcribedText);
          } catch (err) {
            // Nettoyer m√™me en cas d'erreur
            if (fs.existsSync(tempPath)) fs.removeSync(tempPath);
            if (fs.existsSync(mp3Path)) fs.removeSync(mp3Path);
            reject(err);
          }
        })
        .on("error", async (err) => {
          // Si la conversion √©choue, essayer directement avec le fichier PCM
          // Convertir en WAV simple pour Whisper
          const wavPath = tempPath.replace(".pcm", ".wav");
          try {
            await new Promise((resolveWav, rejectWav) => {
              ffmpeg(tempPath)
                .toFormat("wav")
                .audioFrequency(16000)
                .audioChannels(1)
                .audioCodec("pcm_s16le")
                .save(wavPath)
                .on("end", resolveWav)
                .on("error", rejectWav);
            });
            
            const audioFile = fs.createReadStream(wavPath);
            const transcription = await openai.audio.transcriptions.create({
              file: audioFile,
              model: "whisper-1",
              language: "fr",
              response_format: "text"
            });
            
            const text = typeof transcription === 'string' ? transcription.trim() : transcription.text?.trim() || "";
            
            // Nettoyer
            if (fs.existsSync(tempPath)) fs.removeSync(tempPath);
            if (fs.existsSync(wavPath)) fs.removeSync(wavPath);
            
            resolve(text);
          } catch (error) {
            // Nettoyer en cas d'erreur
            if (fs.existsSync(tempPath)) fs.removeSync(tempPath);
            if (fs.existsSync(wavPath)) fs.removeSync(wavPath);
            reject(error);
          }
        });
    });
  } catch (error) {
    console.error("Erreur transcription OpenAI:", error);
    throw new Error("Impossible de transcrire l'audio: " + error.message);
  }
}

// Fonction pour g√©n√©rer du texte avec OpenAI (avec retry pour erreur 429)
async function generateTextWithOpenAI(text, userId, retries = 3) {
  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      const userPrompt =
        userStyles[userId] || "Tu es Jarvis, un assistant intelligent. R√©pond de mani√®re naturelle et respectueuse, avec un ton masculin et un peu dr√¥le.";

      const completion = await openai.chat.completions.create({
        model: "gpt-4o-mini", // Utilise gpt-4o-mini pour un meilleur rapport qualit√©/prix
        messages: [
          {
            role: "system",
            content: userPrompt
          },
          {
            role: "user",
            content: text
          }
        ],
        temperature: 0.7,
        max_tokens: 1000
      });

      const response = completion.choices[0]?.message?.content || "";
      return response.trim();
    } catch (error) {
      // Si erreur 429 (trop de requ√™tes), attendre et r√©essayer
      if (error.status === 429 && attempt < retries) {
        // Extraire le d√©lai sugg√©r√© par l'API si disponible
        let waitTime = Math.pow(2, attempt) * 1000; // Backoff exponentiel: 2s, 4s, 8s
        
        // OpenAI renvoie parfois un header Retry-After
        if (error.headers && error.headers['retry-after']) {
          const suggestedDelay = parseInt(error.headers['retry-after']) * 1000;
          if (suggestedDelay > waitTime) {
            waitTime = suggestedDelay;
          }
        }
        
        console.warn(`‚ö†Ô∏è Erreur 429 (quota d√©pass√©) pour g√©n√©ration texte. Attente de ${waitTime/1000}s avant r√©essai (tentative ${attempt}/${retries})...`);
        await new Promise(resolve => setTimeout(resolve, waitTime));
        continue;
      }
      
      // Si c'est la derni√®re tentative ou une autre erreur, lancer l'erreur
      if (attempt === retries) {
        console.error("‚ùå Erreur g√©n√©ration texte OpenAI apr√®s", retries, "tentatives:", error);
        throw new Error("Impossible de g√©n√©rer une r√©ponse");
      }
    }
  }
}

// Fonction pour cr√©er un fichier audio TTS avec OpenAI TTS
async function createTTSAudio(text, lang = "fr") {
  // Utiliser OpenAI TTS avec voix masculine
  if (openai && process.env.OPENAI_API_KEY) {
    try {
      console.log(`üé§ G√©n√©ration audio avec OpenAI TTS (voix: ${TTS_VOICE})...`);
      
      // G√©n√©rer l'audio avec OpenAI TTS
      const response = await openai.audio.speech.create({
        model: "tts-1",  // Mod√®le TTS rapide
        voice: TTS_VOICE,  // Voix configur√©e (echo, onyx, fable pour masculin)
        input: text,
        speed: TTS_SPEED,  // Vitesse configur√©e (0.25 √† 4.0)
      });

      // Sauvegarder dans un fichier temporaire
      const mp3Path = path.join(__dirname, `temp_${Date.now()}.mp3`);
      const buffer = Buffer.from(await response.arrayBuffer());
      fs.writeFileSync(mp3Path, buffer);

      console.log("‚úÖ Audio g√©n√©r√© avec OpenAI TTS");
      
      // Convertir MP3 en WAV 48kHz mono pour Discord
      const wavPath = mp3Path.replace(".mp3", ".wav");
      
      return new Promise((resolve, reject) => {
        ffmpeg(mp3Path)
          .toFormat("wav")
          .audioFrequency(48000)  // 48kHz pour Discord
          .audioChannels(1)  // Mono
          .audioCodec("pcm_s16le")
          
          .on("end", () => {
            // Nettoyer le fichier MP3
            if (fs.existsSync(mp3Path)) {
              fs.removeSync(mp3Path);
            }
            resolve(wavPath);
          })
          .on("error", (err) => {
            console.warn("‚ö†Ô∏è Erreur conversion WAV, utilisation du MP3:", err);
            // Utiliser le MP3 directement si la conversion √©choue
            resolve(mp3Path);
          })
          .save(wavPath);
      });
    } catch (error) {
      console.error("‚ùå Erreur OpenAI TTS:", error);
      console.log("üîÑ Fallback vers gTTS avec effets...");
      // Fallback vers gTTS avec effets
    }
  }

  // Fallback : utiliser gTTS avec effets audio pour rendre la voix masculine
  const { default: gTTS } = await import("gtts");
  return new Promise((resolve, reject) => {
    const outputPath = path.join(__dirname, `temp_${Date.now()}.mp3`);
    
    try {
      const gtts = new gTTS(text, lang);

      gtts.save(outputPath, (err) => {
        if (err) {
          reject(err);
          return;
        }

        // Convertir MP3 en WAV 48kHz mono avec effets pour voix masculine
        const wavPath = outputPath.replace(".mp3", ".wav");
        
        console.log("üîÑ Conversion audio avec effets voix masculine (gTTS fallback)...");
        
        ffmpeg(outputPath)
          .toFormat("wav")
          .audioFrequency(48000)
          .audioChannels(1)
          .audioCodec("pcm_s16le")
          .audioFilters([
            'asetrate=48000*0.6',  // Voix beaucoup plus grave
            'aresample=48000',
            'atempo=0.9',  // Ralentir de 10%
            'aecho=0.8:0.88:60:0.4'  // √âcho l√©ger
          ])
          .on("end", () => {
            if (fs.existsSync(outputPath)) fs.removeSync(outputPath);
            resolve(wavPath);
          })
          .on("error", (err) => {
            console.error("‚ùå Erreur conversion:", err);
            if (fs.existsSync(outputPath)) fs.removeSync(outputPath);
            reject(err);
          })
          .save(wavPath);
      });
    } catch (error) {
      reject(error);
    }
  });
}

// Fonction Live : √©coute + TTS dans le salon vocal
async function handleVoiceChannel(voiceChannel, guildId, userId) {
  console.log(`üîä Connexion au salon vocal: ${voiceChannel.name}`);
  
  const connection = joinVoiceChannel({
    channelId: voiceChannel.id,
    guildId: guildId,
    adapterCreator: voiceChannel.guild.voiceAdapterCreator,
    selfDeaf: false,  // Ne pas se mettre en sourdine
    selfMute: false,  // Ne pas se mettre en muet
  });

  const receiver = connection.receiver;
  const player = createAudioPlayer();

  // S'abonner au player avant de commencer
  connection.subscribe(player);
  console.log("‚úÖ Player abonn√© √† la connexion vocale");

  // Gestion des erreurs de connexion
  connection.on("error", (error) => {
    console.error("‚ùå Erreur connexion vocale:", error);
    // L'erreur d'encryption est souvent non-bloquante, on continue
    if (error.message && error.message.includes("encryption")) {
      console.warn("‚ö†Ô∏è Erreur d'encryption (peut √™tre ignor√©e si la connexion fonctionne)");
    }
  });

  // Gestion de l'√©tat de la connexion pour d√©boguer
  connection.on("stateChange", (oldState, newState) => {
    if (oldState.status !== newState.status) {
      console.log(`üîÑ √âtat connexion: ${oldState.status} ‚Üí ${newState.status}`);
    }
  });

  // Gestion des erreurs du player
  player.on("error", (error) => {
    console.error("‚ùå Erreur player audio:", error);
  });

  // Message de salutation quand le bot rejoint
  // Attendre un peu que la connexion soit compl√®tement √©tablie
  setTimeout(async () => {
    try {
      console.log("‚úÖ Connexion vocale √©tablie, envoi du message de salutation...");
      
      const greetingMessage = "Salut ! Je suis pr√™t √† discuter avec vous. Parlez-moi et je vous r√©pondrai !";
      const greetingAudioPath = await createTTSAudio(greetingMessage, "fr");
      
      // V√©rifier que la connexion est pr√™te
      if (connection.state.status !== "ready") {
        console.warn(`‚ö†Ô∏è Connexion pas pr√™te (√©tat: ${connection.state.status}), attente...`);
        await new Promise((resolve) => {
          const checkReady = () => {
            if (connection.state.status === "ready") {
              connection.off("stateChange", checkReady);
              resolve();
            }
          };
          connection.on("stateChange", checkReady);
          setTimeout(() => {
            connection.off("stateChange", checkReady);
            resolve();
          }, 5000);
        });
      }

      const resource = createAudioResource(greetingAudioPath, {
        inputType: "file",
      });

      // S'assurer que le player est abonn√©
      connection.subscribe(player);
      console.log("‚úÖ Player abonn√© pour le message de salutation");

      // √âcouter les √©v√©nements
      const greetingPlayingHandler = () => {
        console.log("‚ñ∂Ô∏è Message de salutation en cours de lecture !");
      };
      const greetingIdleHandler = () => {
        console.log("‚èπÔ∏è Message de salutation termin√©");
        setTimeout(() => {
          if (fs.existsSync(greetingAudioPath)) {
            fs.removeSync(greetingAudioPath);
          }
        }, 1000);
        player.off(AudioPlayerStatus.Playing, greetingPlayingHandler);
        player.off(AudioPlayerStatus.Idle, greetingIdleHandler);
      };
      
      player.once(AudioPlayerStatus.Playing, greetingPlayingHandler);
      player.once(AudioPlayerStatus.Idle, greetingIdleHandler);

      console.log("üéµ D√©marrage du message de salutation...");
      player.play(resource);
    } catch (error) {
      console.error("‚ùå Erreur message de salutation:", error);
    }
  }, 1500); // Attendre 1.5 secondes pour que la connexion soit stable

  receiver.speaking.on("start", async (userIdSpeaking) => {
    if (userIdSpeaking === client.user.id) {
      console.log("üîá Ignor√©: audio du bot lui-m√™me");
      return; // Ignorer notre propre audio
    }

    const user = await client.users.fetch(userIdSpeaking).catch(() => null);
    console.log(`üé§ ${user?.username || userIdSpeaking} commence √† parler...`);

    const audioStream = receiver.subscribe(userIdSpeaking, {
      end: { behavior: "silence", duration: 1000 },
    });

    const convert = new prism.opus.Decoder({
      frameSize: 960,
      channels: 1,
      rate: 48000,
    });

    pipeline(audioStream, convert, async (err) => {
      if (err) console.error("Pipeline error:", err);
    });

    let buffer = [];
    convert.on("data", (chunk) => buffer.push(chunk));
    convert.on("end", async () => {
      try {
      const audioBuffer = Buffer.concat(buffer);
        console.log(`üìä Audio re√ßu: ${audioBuffer.length} bytes`);

        if (audioBuffer.length === 0) {
          console.log("‚ö†Ô∏è Buffer audio vide, ignor√©");
          return;
        }

        // Transcription avec OpenAI Whisper
        console.log("üîÑ Transcription en cours...");
        const text = await transcribeAudioWithOpenAI(audioBuffer);
        console.log("üë§ Utilisateur dit:", text);

        if (!text || text.trim().length === 0) {
          console.log("‚ö†Ô∏è Transcription vide, ignor√©");
          return;
        }

        // G√©n√©ration r√©ponse avec OpenAI
        const answer = await generateTextWithOpenAI(text, userIdSpeaking);
        console.log("R√©ponse IA:", answer);

        // Cr√©er fichier audio TTS
        console.log("üé§ G√©n√©ration audio TTS...");
        const audioPath = await createTTSAudio(answer, "fr");
        console.log("‚úÖ Audio g√©n√©r√©:", audioPath);

        // Jouer l'audio dans le salon vocal
        console.log("üîä Pr√©paration de la lecture audio...");
        console.log(`üìÅ Fichier audio: ${audioPath}`);
        console.log(`üìä Taille fichier: ${fs.existsSync(audioPath) ? fs.statSync(audioPath).size : 0} bytes`);
        
        // V√©rifier que la connexion est pr√™te
        if (connection.state.status !== "ready") {
          console.warn(`‚ö†Ô∏è Connexion pas pr√™te (√©tat: ${connection.state.status}), attente...`);
          await new Promise((resolve) => {
            const checkReady = () => {
              if (connection.state.status === "ready") {
                connection.off("stateChange", checkReady);
                resolve();
              }
            };
            connection.on("stateChange", checkReady);
            // Timeout apr√®s 5 secondes
            setTimeout(() => {
              connection.off("stateChange", checkReady);
              resolve();
            }, 5000);
          });
        }

        // Cr√©er la ressource audio
        // Discord.js peut d√©coder automatiquement WAV, MP3, etc.
        let resource;
        try {
          resource = createAudioResource(audioPath, {
            inputType: "file",
          });
          console.log(`‚úÖ Ressource audio cr√©√©e (format: ${audioPath.split('.').pop()})`);
        } catch (error) {
          console.error("‚ùå Erreur cr√©ation ressource:", error);
          throw error;
        }

        // S'assurer que le player est toujours abonn√©
        connection.subscribe(player);
        console.log("‚úÖ Player abonn√© √† la connexion");

        // √âcouter les √©v√©nements du player pour d√©bugger
        const playingHandler = () => {
          console.log("‚ñ∂Ô∏è Audio en cours de lecture !");
        };
        const idleHandler = () => {
          console.log("‚èπÔ∏è Audio termin√©");
          // Nettoyer les fichiers temporaires
          setTimeout(() => {
            if (fs.existsSync(audioPath)) {
              fs.removeSync(audioPath);
              console.log("üóëÔ∏è Fichier audio nettoy√©");
            }
          }, 1000);
          // Retirer les handlers
          player.off(AudioPlayerStatus.Playing, playingHandler);
          player.off(AudioPlayerStatus.Idle, idleHandler);
        };
        const errorHandler = (error) => {
          console.error("‚ùå Erreur lecture audio:", error);
          player.off("error", errorHandler);
        };

        player.once(AudioPlayerStatus.Playing, playingHandler);
        player.once(AudioPlayerStatus.Idle, idleHandler);
        player.once("error", errorHandler);

        // Lire l'audio
        console.log("üéµ D√©marrage de la lecture...");
        player.play(resource);
      } catch (error) {
        console.error("Erreur traitement vocal:", error);
      }
    });
  });
}

// Fonction pour capturer l'√©cran
async function captureScreen() {
  try {
    console.log("üì∏ Capture de l'√©cran en cours...");
    const imgPath = path.join(__dirname, `temp_screen_${Date.now()}.png`);
    await screenshot({ filename: imgPath });
    
    // V√©rifier que le fichier existe
    if (!fs.existsSync(imgPath)) {
      console.error("‚ùå Fichier de capture non cr√©√©");
      return null;
    }
    
    // V√©rifier la taille du fichier
    const stats = fs.statSync(imgPath);
    console.log(`‚úÖ Capture r√©ussie: ${(stats.size / 1024 / 1024).toFixed(2)} MB`);
    
    return imgPath;
  } catch (error) {
    console.error("‚ùå Erreur capture √©cran:", error);
    return null;
  }
}

// Fonction pour capturer la cam√©ra
async function captureWebcam() {
  // V√©rifier si on est sur un serveur cloud (pas de cam√©ra disponible)
  if (process.env.RENDER || process.env.NODE_ENV === "production") {
    console.warn("‚ö†Ô∏è Capture cam√©ra non disponible sur serveur cloud");
    return Promise.reject(new Error("Capture cam√©ra non disponible sur serveur cloud"));
  }
  
  return new Promise((resolve, reject) => {
    try {
      const imgPath = path.join(__dirname, `temp_webcam_${Date.now()}.jpg`);
      
      // V√©rifier si imagesnap est disponible (macOS)
      let hasImagesnap = false;
      try {
        execSync("which imagesnap", { stdio: "ignore" });
        hasImagesnap = true;
      } catch (e) {
        hasImagesnap = false;
      }

      if (!hasImagesnap) {
        // Essayer d'utiliser node-webcam avec une configuration diff√©rente
        console.log("‚ö†Ô∏è imagesnap non disponible, tentative avec node-webcam...");
      }

      // Configuration de la webcam
      const opts = {
        width: 1280,
        height: 720,
        quality: 90,
        delay: 0,
        saveShots: true,
        output: "jpeg",
        device: false, // Utiliser la cam√©ra par d√©faut
        callbackReturn: "location",
        verbose: false
      };

      webcam.capture(imgPath, opts, (err, data) => {
        if (err) {
          console.error("‚ùå Erreur capture cam√©ra:", err.message || err);
          
          // Si imagesnap n'est pas trouv√©, donner des instructions
          if (err.message && err.message.includes("imagesnap")) {
            const errorMsg = "‚ùå imagesnap n'est pas install√©. Pour installer sur macOS: `brew install imagesnap`\n" +
                           "üí° Alternative: Vous pouvez utiliser la capture d'√©cran avec `!screen`";
            reject(new Error(errorMsg));
          } else {
            reject(err);
          }
          return;
        }
        
        // V√©rifier que le fichier existe
        if (fs.existsSync(imgPath)) {
          console.log("‚úÖ Capture cam√©ra r√©ussie");
          resolve(imgPath);
        } else {
          reject(new Error("Fichier cam√©ra non cr√©√©"));
        }
      });
    } catch (error) {
      reject(error);
    }
  });
}

// Fonction pour convertir une image en base64
async function imageToBase64(imagePath) {
  try {
    // Lire directement le fichier et convertir en base64
    const buffer = fs.readFileSync(imagePath);
    return buffer.toString("base64");
  } catch (error) {
    console.error("‚ùå Erreur conversion image:", error);
    throw error;
  }
}

// Fonction helper pour analyser et r√©pondre avec une image
async function analyzeAndRespond(channel, imageAttachment, question, type) {
  try {
    const imageUrl = imageAttachment.url;
    const response = await fetch(imageUrl);
    const arrayBuffer = await response.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);
    
    const ext = imageAttachment.name?.split('.').pop()?.toLowerCase() || 'png';
    const imagePath = path.join(__dirname, `temp_${type}_${Date.now()}.${ext}`);
    fs.writeFileSync(imagePath, buffer);
    
    await channel.send(`üñºÔ∏è Analyse de la capture ${type}...`);
    const description = await analyzeImageWithOpenAI(imagePath, question || null);
    
    const emoji = type === "cam√©ra" ? "üì∑" : "üîç";
    await channel.send({
      content: `${emoji} **Ce que je vois dans cette capture ${type} :**\n${description}`,
    });
    
    setTimeout(() => {
      if (fs.existsSync(imagePath)) fs.removeSync(imagePath);
    }, 60000);
  } catch (error) {
    console.error(`Erreur analyse ${type}:`, error);
    channel.send(`‚ùå Erreur lors de l'analyse de la capture ${type}.`);
  }
}

// Fonction pour analyser une image avec OpenAI Vision (avec retry pour erreur 429)
async function analyzeImageWithOpenAI(imagePath, question = null, retries = 3) {
  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      console.log(`üîç Analyse de l'image avec OpenAI Vision... (tentative ${attempt}/${retries})`);
      
      // Convertir l'image en base64
      const imageBase64 = await imageToBase64(imagePath);
      
      // D√©terminer le type MIME selon l'extension du fichier
      const ext = path.extname(imagePath).toLowerCase();
      let mimeType = "image/png";
      if (ext === ".jpg" || ext === ".jpeg") {
        mimeType = "image/jpeg";
      } else if (ext === ".png") {
        mimeType = "image/png";
      } else if (ext === ".webp") {
        mimeType = "image/webp";
      } else if (ext === ".gif") {
        mimeType = "image/gif";
      }
      
      // Construire le prompt selon la question
      let prompt;
      if (question) {
        prompt = `Tu es Jarvis, un assistant intelligent. L'utilisateur te demande : "${question}". 

Regarde attentivement cette image et r√©ponds-lui directement en utilisant "tu" ou "ton", comme si tu lui parlais en face. 

R√©ponds de mani√®re pr√©cise, naturelle et conversationnelle. D√©cris ce que tu vois et r√©ponds √† sa question. Utilise des phrases compl√®tes et fluides, JAMAIS de listes ou formatage markdown.`;
      } else {
        prompt = `Tu es Jarvis, un assistant intelligent. Tu regardes une image et tu veux d√©crire ce que tu vois.

Parle directement √† l'utilisateur en utilisant "tu" ou "ton", comme si tu lui parlais en face. D√©cris ce que tu vois sur l'image de mani√®re naturelle et conversationnelle.

Commence par d√©crire exactement ce qui est visible, puis si tu d√©tectes des probl√®mes ou opportunit√©s, parle-lui en de mani√®re naturelle.

Utilise des phrases fluides, comme si tu racontais ce que tu vois √† un ami. JAMAIS de listes num√©rot√©es ou formatage markdown.

Sois spontan√© et naturel dans ta description.`;
      }

      // Utiliser OpenAI Vision pour analyser l'image
      const completion = await openai.chat.completions.create({
        model: "gpt-4o-mini", // gpt-4o-mini supporte la vision
        messages: [
          {
            role: "user",
            content: [
              {
                type: "text",
                text: prompt
              },
              {
                type: "image_url",
                image_url: {
                  url: `data:${mimeType};base64,${imageBase64}`
                }
              }
            ]
          }
        ],
        max_tokens: 1000
      });

      const description = completion.choices[0]?.message?.content?.trim() || "";
      
      console.log("‚úÖ Analyse termin√©e");
      return description;
    } catch (error) {
      // Si erreur 429 (trop de requ√™tes), attendre et r√©essayer
      if (error.status === 429 && attempt < retries) {
        let waitTime = Math.pow(2, attempt) * 1000; // Backoff exponentiel: 2s, 4s, 8s
        
        // OpenAI renvoie parfois un header Retry-After
        if (error.headers && error.headers['retry-after']) {
          const suggestedDelay = parseInt(error.headers['retry-after']) * 1000;
          if (suggestedDelay > waitTime) {
            waitTime = suggestedDelay;
          }
        }
        
        console.warn(`‚ö†Ô∏è Erreur 429 (trop de requ√™tes). Attente de ${waitTime/1000}s avant r√©essai...`);
        await new Promise(resolve => setTimeout(resolve, waitTime));
        continue;
      }
      
      // Si c'est la derni√®re tentative ou une autre erreur, lancer l'erreur
      if (attempt === retries) {
        console.error("‚ùå Erreur analyse image apr√®s", retries, "tentatives:", error);
        throw error;
      }
    }
  }
}

// Fonction pour envoyer un message vocal dans un chat texte
async function sendVoiceMessage(channel, text, userId) {
  try {
    // G√©n√©rer la r√©ponse avec OpenAI
    const answer = await generateTextWithOpenAI(text, userId);

    // Cr√©er le fichier audio
    const audioPath = await createTTSAudio(answer, "fr");

    // Envoyer le fichier audio comme pi√®ce jointe
    const attachment = new AttachmentBuilder(audioPath, {
      name: "message_vocal.opus",
      description: answer,
    });

    await channel.send({
      files: [attachment],
      content: `üé§ **R√©ponse vocale:**\n${answer}`,
    });

    // Nettoyer le fichier temporaire
    setTimeout(() => {
      if (fs.existsSync(audioPath)) {
        fs.removeSync(audioPath);
      }
    }, 5000);
  } catch (error) {
    console.error("Erreur envoi message vocal:", error);
    channel.send("‚ùå Erreur lors de la g√©n√©ration du message vocal.");
  }
}

client.on("messageCreate", async (message) => {
  if (message.author.bot) return;

  // Commande pour rejoindre un salon vocal
  if (message.content.startsWith("!join")) {
    const voiceChannel = message.member?.voice.channel;
    if (!voiceChannel)
      return message.reply("üîä Rejoins d'abord un salon vocal !");
    
    await handleVoiceChannel(voiceChannel, message.guild.id, message.author.id);
    message.reply("‚úÖ Bot pr√™t √† √©couter et parler !");
    return;
  }

  // Commande pour quitter le salon vocal
  if (message.content.startsWith("!leave")) {
    const connection = getVoiceConnection(message.guild.id);
    if (connection) {
      connection.destroy();
      message.reply("üëã J'ai quitt√© le salon vocal.");
    } else {
      message.reply("‚ùå Je ne suis dans aucun salon vocal.");
    }
    return;
  }

  // Commande pour envoyer un message vocal dans le chat
  if (message.content.startsWith("!voice") || message.content.startsWith("!vocal")) {
    const text = message.content.slice(message.content.indexOf(" ") + 1).trim();
    if (!text) {
      return message.reply("‚ùå Utilise: `!voice [votre message]` ou `!vocal [votre message]`");
    }
    
    await sendVoiceMessage(message.channel, text, message.author.id);
    return;
  }

  // Commande pour voir la cam√©ra
  if (message.content.startsWith("!camera") || message.content.startsWith("!cam") || message.content.startsWith("!visio")) {
    // Extraire la question si pr√©sente
    const question = message.content.slice(message.content.indexOf(" ") + 1).trim() || null;
    
    // Envoyer une demande de capture au script client local (si disponible)
    await message.reply("üì∑ **Capture cam√©ra demand√©e...**\n\nüí° Si tu as le script client tournant sur ton PC, la capture sera automatique.\n\nüì± **Pour t√©l√©phone/tablette :** Envoie-moi une photo directement dans le chat et je l'analyserai !");
    
    // Envoyer un message sp√©cial que le script client peut d√©tecter
    await message.channel.send("CAPTURE_REQUEST:CAMERA");
    
    // Attendre 10 secondes pour voir si une image arrive
    const collector = message.channel.createMessageCollector({
      filter: (msg) => msg.author.id === message.author.id && msg.attachments.size > 0,
      time: 10000,
      max: 1
    });
    
    collector.on("collect", async (collectedMessage) => {
      const imageAttachment = collectedMessage.attachments.first();
      if (imageAttachment && imageAttachment.contentType?.startsWith("image/")) {
        await analyzeAndRespond(message.channel, imageAttachment, question, "cam√©ra");
      }
    });
    
    // Aussi d√©tecter les images envoy√©es par le script client (qui pourrait √™tre un autre bot)
    const clientCollector = message.channel.createMessageCollector({
      filter: (msg) => {
        // D√©tecter les messages avec images contenant "Capture cam√©ra depuis ton PC"
        return msg.attachments.size > 0 && 
               (msg.content.includes("Capture cam√©ra") || msg.content.includes("Capture cam√©ra depuis"));
      },
      time: 15000,
      max: 1
    });
    
    clientCollector.on("collect", async (collectedMessage) => {
      const imageAttachment = collectedMessage.attachments.first();
      if (imageAttachment && imageAttachment.contentType?.startsWith("image/")) {
        await analyzeAndRespond(message.channel, imageAttachment, question, "cam√©ra");
      }
    });
    
    collector.on("end", (collected) => {
      if (collected.size === 0) {
        // Si aucune image n'a √©t√© re√ßue, le script client n'est peut-√™tre pas actif
        // On laisse l'utilisateur envoyer une image manuellement
      }
    });
    
    return;
  }

  // Commande pour voir l'√©cran
  if (message.content.startsWith("!screen") || message.content.startsWith("!ecran") || message.content.startsWith("!analyse")) {
    // Extraire la question si pr√©sente
    const question = message.content.slice(message.content.indexOf(" ") + 1).trim() || null;
    
    // Envoyer une demande de capture au script client local (si disponible)
    await message.reply("üîç **Capture d'√©cran demand√©e...**\n\nüí° Si tu as le script client tournant sur ton PC, la capture sera automatique.\n\nüì± **Pour t√©l√©phone/tablette :** Envoie-moi une capture d'√©cran directement dans le chat et je l'analyserai !");
    
    // Envoyer un message sp√©cial que le script client peut d√©tecter
    await message.channel.send("CAPTURE_REQUEST:SCREEN");
    
    // Attendre 10 secondes pour voir si une image arrive
    const collector = message.channel.createMessageCollector({
      filter: (msg) => msg.author.id === message.author.id && msg.attachments.size > 0,
      time: 10000,
      max: 1
    });
    
    collector.on("collect", async (collectedMessage) => {
      const imageAttachment = collectedMessage.attachments.first();
      if (imageAttachment && imageAttachment.contentType?.startsWith("image/")) {
        await analyzeAndRespond(message.channel, imageAttachment, question, "√©cran");
      }
    });
    
    // Aussi d√©tecter les images envoy√©es par le script client (qui pourrait √™tre un autre bot)
    const clientCollector = message.channel.createMessageCollector({
      filter: (msg) => {
        // D√©tecter les messages avec images contenant "Capture d'√©cran depuis ton PC"
        return msg.attachments.size > 0 && 
               (msg.content.includes("Capture d'√©cran") || msg.content.includes("Capture d'√©cran depuis"));
      },
      time: 15000,
      max: 1
    });
    
    clientCollector.on("collect", async (collectedMessage) => {
      const imageAttachment = collectedMessage.attachments.first();
      if (imageAttachment && imageAttachment.contentType?.startsWith("image/")) {
        await analyzeAndRespond(message.channel, imageAttachment, question, "√©cran");
      }
    });
    
    return;
  }

  // Analyser les images envoy√©es dans Discord (depuis n'importe quel appareil)
  // Ignorer si c'est une r√©ponse √† une demande de capture (d√©j√† g√©r√© par les collectors)
  if (message.attachments.size > 0 && !message.reference) {
    const imageAttachments = message.attachments.filter(attachment => {
      // V√©rifier le type MIME
      if (attachment.contentType && attachment.contentType.startsWith("image/")) {
        return true;
      }
      // V√©rifier aussi l'extension du nom de fichier (pour compatibilit√©)
      const ext = attachment.name?.split('.').pop()?.toLowerCase();
      return ext && ['png', 'jpg', 'jpeg', 'gif', 'webp', 'bmp'].includes(ext);
    });

    if (imageAttachments.size > 0) {
      // Extraire la question du message si pr√©sente
      const question = message.content.replace(`<@${client.user.id}>`, "").trim() || null;
      
      await message.reply("üñºÔ∏è Analyse de l'image en cours... (depuis ton appareil)");

      try {
        // Prendre la premi√®re image
        const imageAttachment = imageAttachments.first();
        const imageUrl = imageAttachment.url;

        console.log(`üì• Image re√ßue depuis ${message.author.username} (${message.author.id}): ${imageAttachment.name} (${(imageAttachment.size / 1024).toFixed(2)} KB)`);

        // T√©l√©charger l'image
        const response = await fetch(imageUrl);
        if (!response.ok) {
          throw new Error(`Erreur t√©l√©chargement: ${response.status}`);
        }
        const arrayBuffer = await response.arrayBuffer();
        const buffer = Buffer.from(arrayBuffer);

        // D√©terminer l'extension
        const ext = imageAttachment.name?.split('.').pop()?.toLowerCase() || 
                   imageAttachment.contentType?.split('/')[1]?.split(';')[0] || 
                   'png';

        // Sauvegarder temporairement
        const imagePath = path.join(__dirname, `temp_discord_${Date.now()}.${ext}`);
        fs.writeFileSync(imagePath, buffer);

        console.log(`‚úÖ Image sauvegard√©e: ${imagePath} (${(buffer.length / 1024).toFixed(2)} KB)`);

        // Analyser l'image avec OpenAI Vision
        const description = await analyzeImageWithOpenAI(imagePath, question || null);

        await message.channel.send({
          content: `üñºÔ∏è **Ce que je vois dans cette image :**\n${description}`,
        });

        // Nettoyer le fichier temporaire
        setTimeout(() => {
          if (fs.existsSync(imagePath)) {
            fs.removeSync(imagePath);
            console.log(`üóëÔ∏è Fichier temporaire supprim√©: ${imagePath}`);
          }
        }, 60000);
      } catch (error) {
        console.error("‚ùå Erreur analyse image Discord:", error);
        let errorMsg = "‚ùå Erreur lors de l'analyse de l'image.";
        
        if (error.status === 429) {
          errorMsg = "‚ùå Trop de requ√™tes vers OpenAI API (quota d√©pass√©). Attends quelques secondes et r√©essaye. Le bot va automatiquement r√©essayer avec un d√©lai.";
        } else if (error.message && error.message.includes("t√©l√©chargement")) {
          errorMsg = "‚ùå Erreur lors du t√©l√©chargement de l'image. V√©rifie que l'image est valide et r√©essaye.";
        }
        
        await message.reply(errorMsg);
      }
      return;
    }
  }

  // R√©pondre aux messages mentionnant le bot ou commen√ßant par "!"
  const mentioned = message.mentions.has(client.user);
  const isCommand = message.content.startsWith("!");
  
  if (mentioned || (isCommand && !message.content.startsWith("!join") && !message.content.startsWith("!leave") && !message.content.startsWith("!voice") && !message.content.startsWith("!vocal") && !message.content.startsWith("!camera") && !message.content.startsWith("!cam") && !message.content.startsWith("!visio") && !message.content.startsWith("!screen") && !message.content.startsWith("!ecran") && !message.content.startsWith("!analyse"))) {
    try {
      const userMessage = message.content.replace(`<@${client.user.id}>`, "").trim();
      const answer = await generateTextWithOpenAI(userMessage, message.author.id);
      await message.reply(answer);
    } catch (error) {
      console.error("Erreur r√©ponse texte:", error);
      let errorMsg = "‚ùå D√©sol√©, une erreur s'est produite.";
      
      if (error.message && error.message.includes("quota")) {
        errorMsg = "‚ùå Quota API d√©pass√©. Attends quelques secondes et r√©essaye. Le bot va automatiquement r√©essayer avec un d√©lai.";
      }
      
      message.reply(errorMsg);
    }
  }
});

// D√©marrer un serveur HTTP simple pour Render (d√©tection de port)
const PORT = process.env.PORT || 3000;

const server = http.createServer((req, res) => {
  res.writeHead(200, { "Content-Type": "text/plain" });
  res.end("Bot Discord en ligne !");
});

server.listen(PORT, () => {
  console.log(`üåê Serveur HTTP d√©marr√© sur le port ${PORT} (pour Render)`);
});

// Connexion du bot Discord
client.login(process.env.DISCORD_TOKEN);

