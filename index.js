import { Client, GatewayIntentBits, AttachmentBuilder } from "discord.js";
import {
  joinVoiceChannel,
  getVoiceConnection,
  createAudioPlayer,
  createAudioResource,
  AudioPlayerStatus,
} from "@discordjs/voice";
import { GoogleGenerativeAI } from "@google/generative-ai";
import OpenAI from "openai";
import dotenv from "dotenv";
import { pipeline } from "stream";
import prism from "prism-media";
import fs from "fs-extra";
import path from "path";
import { fileURLToPath } from "url";
import ffmpeg from "fluent-ffmpeg";
import screenshot from "screenshot-desktop";
import webcam from "node-webcam";

dotenv.config();

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const client = new Client({
  intents: [
    GatewayIntentBits.Guilds,
    GatewayIntentBits.GuildMessages,
    GatewayIntentBits.MessageContent,
    GatewayIntentBits.GuildVoiceStates,
  ],
});

// Initialiser Gemini
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || "");
const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash-exp" });

// Initialiser OpenAI pour TTS (comme dans votre code Python)
const openaiTTS = new OpenAI({ apiKey: process.env.OPENAI_API_KEY || "" });

// Configuration de la voix TTS
// Options disponibles : "alloy" (neutre), "echo" (masculine), "fable" (masculine), 
//                       "onyx" (masculine profonde), "nova" (f√©minine), "shimmer" (f√©minine douce)
const TTS_VOICE = process.env.JARVIS_TTS_VOICE || "echo";  // Voix masculine par d√©faut (comme Jarvis)
const TTS_SPEED = parseFloat(process.env.JARVIS_TTS_SPEED || "0.95");  // Vitesse de la voix

// Styles selon l'utilisateur
const userStyles = {
  "729630625518190603": "R√©pond de fa√ßon sarcastique.",
  "414754147556917258": "R√©pond avec respect comme un roi.",
};

client.once("ready", () => {
  console.log(`ü§ñ Connect√© en tant que ${client.user.tag}`);
});

// Fonction pour transcrire l'audio avec Gemini
async function transcribeAudioWithGemini(audioBuffer) {
  try {
    // Convertir l'audio en base64
    const base64Audio = audioBuffer.toString("base64");
    
    // Sauvegarder temporairement pour conversion si n√©cessaire
    const tempPath = path.join(__dirname, `temp_transcribe_${Date.now()}.pcm`);
    fs.writeFileSync(tempPath, audioBuffer);
    
    // Convertir en format WAV pour meilleure compatibilit√©
    const wavPath = tempPath.replace(".pcm", ".wav");
    
    return new Promise((resolve, reject) => {
      ffmpeg(tempPath)
        .toFormat("wav")
        .audioFrequency(16000)
        .audioChannels(1)
        .audioCodec("pcm_s16le")
        .save(wavPath)
        .on("end", async () => {
          try {
            // Lire le fichier WAV et convertir en base64
            const wavBuffer = fs.readFileSync(wavPath);
            const base64Wav = wavBuffer.toString("base64");
            
            // Utiliser Gemini pour la transcription audio
            const result = await model.generateContent([
              {
                inlineData: {
                  mimeType: "audio/wav",
                  data: base64Wav,
                },
              },
              {
                text: "Transcris cet audio en texte fran√ßais. Retourne uniquement le texte transcrit, sans commentaires suppl√©mentaires.",
              },
            ]);

            const response = await result.response;
            const transcribedText = response.text().trim();
            
            // Nettoyer les fichiers temporaires
            fs.removeSync(tempPath);
            fs.removeSync(wavPath);
            
            resolve(transcribedText);
          } catch (err) {
            // Nettoyer m√™me en cas d'erreur
            if (fs.existsSync(tempPath)) fs.removeSync(tempPath);
            if (fs.existsSync(wavPath)) fs.removeSync(wavPath);
            reject(err);
          }
        })
        .on("error", (err) => {
          // Si la conversion √©choue, essayer directement avec le buffer original
          fs.removeSync(tempPath);
          
          const base64Audio = audioBuffer.toString("base64");
          model.generateContent([
            {
              inlineData: {
                mimeType: "audio/pcm",
                data: base64Audio,
              },
            },
            {
              text: "Transcris cet audio en texte fran√ßais. Retourne uniquement le texte transcrit.",
            },
          ])
          .then((result) => result.response.text())
          .then(resolve)
          .catch(reject);
        });
    });
  } catch (error) {
    console.error("Erreur transcription Gemini:", error);
    throw new Error("Impossible de transcrire l'audio: " + error.message);
  }
}

// Fonction pour g√©n√©rer du texte avec Gemini
async function generateTextWithGemini(text, userId) {
  try {
    const userPrompt =
      userStyles[userId] || "R√©pond de mani√®re naturelle et respectueuse.";

    const prompt = `${userPrompt}\n\nUtilisateur: ${text}\nAssistant:`;

    const result = await model.generateContent(prompt);
    const response = await result.response;
    return response.text();
  } catch (error) {
    console.error("Erreur g√©n√©ration texte Gemini:", error);
    throw new Error("Impossible de g√©n√©rer une r√©ponse");
  }
}

// Fonction pour cr√©er un fichier audio TTS avec OpenAI TTS (comme dans votre code Python)
async function createTTSAudio(text, lang = "fr") {
  // Utiliser OpenAI TTS avec voix masculine (comme dans votre code Python)
  if (openaiTTS && process.env.OPENAI_API_KEY) {
    try {
      console.log(`üé§ G√©n√©ration audio avec OpenAI TTS (voix: ${TTS_VOICE})...`);
      
      // G√©n√©rer l'audio avec OpenAI TTS (comme dans votre code Python)
      const response = await openaiTTS.audio.speech.create({
        model: "tts-1",  // Mod√®le TTS rapide
        voice: TTS_VOICE,  // Voix configur√©e (echo, onyx, fable pour masculin)
        input: text,
        speed: TTS_SPEED,  // Vitesse configur√©e (0.25 √† 4.0)
      });

      // Sauvegarder dans un fichier temporaire
      const mp3Path = path.join(__dirname, `temp_${Date.now()}.mp3`);
      const buffer = Buffer.from(await response.arrayBuffer());
      fs.writeFileSync(mp3Path, buffer);

      console.log("‚úÖ Audio g√©n√©r√© avec OpenAI TTS");
      
      // Convertir MP3 en WAV 48kHz mono pour Discord
      const wavPath = mp3Path.replace(".mp3", ".wav");
      
      return new Promise((resolve, reject) => {
        ffmpeg(mp3Path)
          .toFormat("wav")
          .audioFrequency(48000)  // 48kHz pour Discord
          .audioChannels(1)  // Mono
          .audioCodec("pcm_s16le")
          
          .on("end", () => {
            // Nettoyer le fichier MP3
            if (fs.existsSync(mp3Path)) {
              fs.removeSync(mp3Path);
            }
            resolve(wavPath);
          })
          .on("error", (err) => {
            console.warn("‚ö†Ô∏è Erreur conversion WAV, utilisation du MP3:", err);
            // Utiliser le MP3 directement si la conversion √©choue
            resolve(mp3Path);
          })
          .save(wavPath);
      });
    } catch (error) {
      console.error("‚ùå Erreur OpenAI TTS:", error);
      console.log("üîÑ Fallback vers gTTS avec effets...");
      // Fallback vers gTTS avec effets
    }
  }

  // Fallback : utiliser gTTS avec effets audio pour rendre la voix masculine
  const { default: gTTS } = await import("gtts");
  return new Promise((resolve, reject) => {
    const outputPath = path.join(__dirname, `temp_${Date.now()}.mp3`);
    
    try {
      const gtts = new gTTS(text, lang);

      gtts.save(outputPath, (err) => {
        if (err) {
          reject(err);
          return;
        }

        // Convertir MP3 en WAV 48kHz mono avec effets pour voix masculine
        const wavPath = outputPath.replace(".mp3", ".wav");
        
        console.log("üîÑ Conversion audio avec effets voix masculine (gTTS fallback)...");
        
        ffmpeg(outputPath)
          .toFormat("wav")
          .audioFrequency(48000)
          .audioChannels(1)
          .audioCodec("pcm_s16le")
          .audioFilters([
            'asetrate=48000*0.6',  // Voix beaucoup plus grave
            'aresample=48000',
            'atempo=0.9',  // Ralentir de 10%
            'aecho=0.8:0.88:60:0.4'  // √âcho l√©ger
          ])
          .on("end", () => {
            if (fs.existsSync(outputPath)) fs.removeSync(outputPath);
            resolve(wavPath);
          })
          .on("error", (err) => {
            console.error("‚ùå Erreur conversion:", err);
            if (fs.existsSync(outputPath)) fs.removeSync(outputPath);
            reject(err);
          })
          .save(wavPath);
      });
    } catch (error) {
      reject(error);
    }
  });
}

// Fonction Live : √©coute + TTS dans le salon vocal
async function handleVoiceChannel(voiceChannel, guildId, userId) {
  console.log(`üîä Connexion au salon vocal: ${voiceChannel.name}`);
  
  const connection = joinVoiceChannel({
    channelId: voiceChannel.id,
    guildId: guildId,
    adapterCreator: voiceChannel.guild.voiceAdapterCreator,
    selfDeaf: false,  // Ne pas se mettre en sourdine
    selfMute: false,  // Ne pas se mettre en muet
  });

  const receiver = connection.receiver;
  const player = createAudioPlayer();

  // S'abonner au player avant de commencer
  connection.subscribe(player);
  console.log("‚úÖ Player abonn√© √† la connexion vocale");

  // Gestion des erreurs de connexion
  connection.on("error", (error) => {
    console.error("‚ùå Erreur connexion vocale:", error);
    // L'erreur d'encryption est souvent non-bloquante, on continue
    if (error.message && error.message.includes("encryption")) {
      console.warn("‚ö†Ô∏è Erreur d'encryption (peut √™tre ignor√©e si la connexion fonctionne)");
    }
  });

  // Gestion de l'√©tat de la connexion pour d√©boguer
  connection.on("stateChange", (oldState, newState) => {
    if (oldState.status !== newState.status) {
      console.log(`üîÑ √âtat connexion: ${oldState.status} ‚Üí ${newState.status}`);
    }
  });

  // Gestion des erreurs du player
  player.on("error", (error) => {
    console.error("‚ùå Erreur player audio:", error);
  });

  // Message de salutation quand le bot rejoint
  // Attendre un peu que la connexion soit compl√®tement √©tablie
  setTimeout(async () => {
    try {
      console.log("‚úÖ Connexion vocale √©tablie, envoi du message de salutation...");
      
      const greetingMessage = "Salut ! Je suis pr√™t √† discuter avec vous. Parlez-moi et je vous r√©pondrai !";
      const greetingAudioPath = await createTTSAudio(greetingMessage, "fr");
      
      // V√©rifier que la connexion est pr√™te
      if (connection.state.status !== "ready") {
        console.warn(`‚ö†Ô∏è Connexion pas pr√™te (√©tat: ${connection.state.status}), attente...`);
        await new Promise((resolve) => {
          const checkReady = () => {
            if (connection.state.status === "ready") {
              connection.off("stateChange", checkReady);
              resolve();
            }
          };
          connection.on("stateChange", checkReady);
          setTimeout(() => {
            connection.off("stateChange", checkReady);
            resolve();
          }, 5000);
        });
      }

      const resource = createAudioResource(greetingAudioPath, {
        inputType: "file",
      });

      // S'assurer que le player est abonn√©
      connection.subscribe(player);
      console.log("‚úÖ Player abonn√© pour le message de salutation");

      // √âcouter les √©v√©nements
      const greetingPlayingHandler = () => {
        console.log("‚ñ∂Ô∏è Message de salutation en cours de lecture !");
      };
      const greetingIdleHandler = () => {
        console.log("‚èπÔ∏è Message de salutation termin√©");
        setTimeout(() => {
          if (fs.existsSync(greetingAudioPath)) {
            fs.removeSync(greetingAudioPath);
          }
        }, 1000);
        player.off(AudioPlayerStatus.Playing, greetingPlayingHandler);
        player.off(AudioPlayerStatus.Idle, greetingIdleHandler);
      };
      
      player.once(AudioPlayerStatus.Playing, greetingPlayingHandler);
      player.once(AudioPlayerStatus.Idle, greetingIdleHandler);

      console.log("üéµ D√©marrage du message de salutation...");
      player.play(resource);
    } catch (error) {
      console.error("‚ùå Erreur message de salutation:", error);
    }
  }, 1500); // Attendre 1.5 secondes pour que la connexion soit stable

  receiver.speaking.on("start", async (userIdSpeaking) => {
    if (userIdSpeaking === client.user.id) {
      console.log("üîá Ignor√©: audio du bot lui-m√™me");
      return; // Ignorer notre propre audio
    }

    const user = await client.users.fetch(userIdSpeaking).catch(() => null);
    console.log(`üé§ ${user?.username || userIdSpeaking} commence √† parler...`);

    const audioStream = receiver.subscribe(userIdSpeaking, {
      end: { behavior: "silence", duration: 1000 },
    });

    const convert = new prism.opus.Decoder({
      frameSize: 960,
      channels: 1,
      rate: 48000,
    });

    pipeline(audioStream, convert, async (err) => {
      if (err) console.error("Pipeline error:", err);
    });

    let buffer = [];
    convert.on("data", (chunk) => buffer.push(chunk));
    convert.on("end", async () => {
      try {
        const audioBuffer = Buffer.concat(buffer);
        console.log(`üìä Audio re√ßu: ${audioBuffer.length} bytes`);

        if (audioBuffer.length === 0) {
          console.log("‚ö†Ô∏è Buffer audio vide, ignor√©");
          return;
        }

        // Transcription avec Gemini
        console.log("üîÑ Transcription en cours...");
        const text = await transcribeAudioWithGemini(audioBuffer);
        console.log("üë§ Utilisateur dit:", text);

        if (!text || text.trim().length === 0) {
          console.log("‚ö†Ô∏è Transcription vide, ignor√©");
          return;
        }

        // G√©n√©ration r√©ponse avec Gemini
        const answer = await generateTextWithGemini(text, userIdSpeaking);
        console.log("R√©ponse IA:", answer);

        // Cr√©er fichier audio TTS
        console.log("üé§ G√©n√©ration audio TTS...");
        const audioPath = await createTTSAudio(answer, "fr");
        console.log("‚úÖ Audio g√©n√©r√©:", audioPath);

        // Jouer l'audio dans le salon vocal
        console.log("üîä Pr√©paration de la lecture audio...");
        console.log(`üìÅ Fichier audio: ${audioPath}`);
        console.log(`üìä Taille fichier: ${fs.existsSync(audioPath) ? fs.statSync(audioPath).size : 0} bytes`);
        
        // V√©rifier que la connexion est pr√™te
        if (connection.state.status !== "ready") {
          console.warn(`‚ö†Ô∏è Connexion pas pr√™te (√©tat: ${connection.state.status}), attente...`);
          await new Promise((resolve) => {
            const checkReady = () => {
              if (connection.state.status === "ready") {
                connection.off("stateChange", checkReady);
                resolve();
              }
            };
            connection.on("stateChange", checkReady);
            // Timeout apr√®s 5 secondes
            setTimeout(() => {
              connection.off("stateChange", checkReady);
              resolve();
            }, 5000);
          });
        }

        // Cr√©er la ressource audio
        // Discord.js peut d√©coder automatiquement WAV, MP3, etc.
        let resource;
        try {
          resource = createAudioResource(audioPath, {
            inputType: "file",
          });
          console.log(`‚úÖ Ressource audio cr√©√©e (format: ${audioPath.split('.').pop()})`);
        } catch (error) {
          console.error("‚ùå Erreur cr√©ation ressource:", error);
          throw error;
        }

        // S'assurer que le player est toujours abonn√©
        connection.subscribe(player);
        console.log("‚úÖ Player abonn√© √† la connexion");

        // √âcouter les √©v√©nements du player pour d√©bugger
        const playingHandler = () => {
          console.log("‚ñ∂Ô∏è Audio en cours de lecture !");
        };
        const idleHandler = () => {
          console.log("‚èπÔ∏è Audio termin√©");
          // Nettoyer les fichiers temporaires
          setTimeout(() => {
            if (fs.existsSync(audioPath)) {
              fs.removeSync(audioPath);
              console.log("üóëÔ∏è Fichier audio nettoy√©");
            }
          }, 1000);
          // Retirer les handlers
          player.off(AudioPlayerStatus.Playing, playingHandler);
          player.off(AudioPlayerStatus.Idle, idleHandler);
        };
        const errorHandler = (error) => {
          console.error("‚ùå Erreur lecture audio:", error);
          player.off("error", errorHandler);
        };

        player.once(AudioPlayerStatus.Playing, playingHandler);
        player.once(AudioPlayerStatus.Idle, idleHandler);
        player.once("error", errorHandler);

        // Lire l'audio
        console.log("üéµ D√©marrage de la lecture...");
        player.play(resource);
      } catch (error) {
        console.error("Erreur traitement vocal:", error);
      }
    });
  });
}

// Fonction pour capturer l'√©cran
async function captureScreen() {
  try {
    console.log("üì∏ Capture de l'√©cran en cours...");
    const imgPath = path.join(__dirname, `temp_screen_${Date.now()}.png`);
    await screenshot({ filename: imgPath });
    
    // V√©rifier que le fichier existe
    if (!fs.existsSync(imgPath)) {
      console.error("‚ùå Fichier de capture non cr√©√©");
      return null;
    }
    
    // V√©rifier la taille du fichier
    const stats = fs.statSync(imgPath);
    console.log(`‚úÖ Capture r√©ussie: ${(stats.size / 1024 / 1024).toFixed(2)} MB`);
    
    return imgPath;
  } catch (error) {
    console.error("‚ùå Erreur capture √©cran:", error);
    return null;
  }
}

// Fonction pour capturer la cam√©ra
async function captureWebcam() {
  return new Promise((resolve, reject) => {
    try {
      const imgPath = path.join(__dirname, `temp_webcam_${Date.now()}.jpg`);
      
      // V√©rifier si imagesnap est disponible (macOS)
      let hasImagesnap = false;
      try {
        execSync("which imagesnap", { stdio: "ignore" });
        hasImagesnap = true;
      } catch (e) {
        hasImagesnap = false;
      }

      if (!hasImagesnap) {
        // Essayer d'utiliser node-webcam avec une configuration diff√©rente
        console.log("‚ö†Ô∏è imagesnap non disponible, tentative avec node-webcam...");
      }

      // Configuration de la webcam
      const opts = {
        width: 1280,
        height: 720,
        quality: 90,
        delay: 0,
        saveShots: true,
        output: "jpeg",
        device: false, // Utiliser la cam√©ra par d√©faut
        callbackReturn: "location",
        verbose: false
      };

      webcam.capture(imgPath, opts, (err, data) => {
        if (err) {
          console.error("‚ùå Erreur capture cam√©ra:", err.message || err);
          
          // Si imagesnap n'est pas trouv√©, donner des instructions
          if (err.message && err.message.includes("imagesnap")) {
            const errorMsg = "‚ùå imagesnap n'est pas install√©. Pour installer sur macOS: `brew install imagesnap`\n" +
                           "üí° Alternative: Vous pouvez utiliser la capture d'√©cran avec `!screen`";
            reject(new Error(errorMsg));
          } else {
            reject(err);
          }
          return;
        }
        
        // V√©rifier que le fichier existe
        if (fs.existsSync(imgPath)) {
          console.log("‚úÖ Capture cam√©ra r√©ussie");
          resolve(imgPath);
        } else {
          reject(new Error("Fichier cam√©ra non cr√©√©"));
        }
      });
    } catch (error) {
      reject(error);
    }
  });
}

// Fonction pour convertir une image en base64
async function imageToBase64(imagePath) {
  try {
    // Lire directement le fichier et convertir en base64
    const buffer = fs.readFileSync(imagePath);
    return buffer.toString("base64");
  } catch (error) {
    console.error("‚ùå Erreur conversion image:", error);
    throw error;
  }
}

// Fonction pour analyser une image avec Gemini Vision (avec retry pour erreur 429)
async function analyzeImageWithGemini(imagePath, question = null, retries = 3) {
  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      console.log(`üîç Analyse de l'image avec Gemini Vision... (tentative ${attempt}/${retries})`);
      
      // Convertir l'image en base64
      const imageBase64 = await imageToBase64(imagePath);
      
      // Construire le prompt selon la question
      let prompt;
      if (question) {
        prompt = `Tu es Jarvis, un assistant intelligent. L'utilisateur te demande : "${question}". 

Regarde attentivement cette image et r√©ponds-lui directement en utilisant "tu" ou "ton", comme si tu lui parlais en face. 

R√©ponds de mani√®re pr√©cise, naturelle et conversationnelle. D√©cris ce que tu vois et r√©ponds √† sa question. Utilise des phrases compl√®tes et fluides, JAMAIS de listes ou formatage markdown.`;
      } else {
        prompt = `Tu es Jarvis, un assistant intelligent. Tu regardes une image et tu veux d√©crire ce que tu vois.

Parle directement √† l'utilisateur en utilisant "tu" ou "ton", comme si tu lui parlais en face. D√©cris ce que tu vois sur l'image de mani√®re naturelle et conversationnelle.

Commence par d√©crire exactement ce qui est visible, puis si tu d√©tectes des probl√®mes ou opportunit√©s, parle-lui en de mani√®re naturelle.

Utilise des phrases fluides, comme si tu racontais ce que tu vois √† un ami. JAMAIS de listes num√©rot√©es ou formatage markdown.

Sois spontan√© et naturel dans ta description.`;
      }

      // D√©terminer le type MIME selon l'extension du fichier
      const ext = path.extname(imagePath).toLowerCase();
      let mimeType = "image/png";
      if (ext === ".jpg" || ext === ".jpeg") {
        mimeType = "image/jpeg";
      } else if (ext === ".png") {
        mimeType = "image/png";
      }

      // Utiliser Gemini Vision pour analyser l'image
      const result = await model.generateContent([
        {
          inlineData: {
            mimeType: mimeType,
            data: imageBase64,
          },
        },
        {
          text: prompt,
        },
      ]);

      const response = await result.response;
      const description = response.text().trim();
      
      console.log("‚úÖ Analyse termin√©e");
      return description;
    } catch (error) {
      // Si erreur 429 (trop de requ√™tes), attendre et r√©essayer
      if (error.status === 429 && attempt < retries) {
        const waitTime = Math.pow(2, attempt) * 1000; // Backoff exponentiel: 2s, 4s, 8s
        console.warn(`‚ö†Ô∏è Erreur 429 (trop de requ√™tes). Attente de ${waitTime/1000}s avant r√©essai...`);
        await new Promise(resolve => setTimeout(resolve, waitTime));
        continue;
      }
      
      // Si c'est la derni√®re tentative ou une autre erreur, lancer l'erreur
      if (attempt === retries) {
        console.error("‚ùå Erreur analyse image apr√®s", retries, "tentatives:", error);
        throw error;
      }
    }
  }
}

// Fonction pour envoyer un message vocal dans un chat texte
async function sendVoiceMessage(channel, text, userId) {
  try {
    // G√©n√©rer la r√©ponse avec Gemini
    const answer = await generateTextWithGemini(text, userId);

    // Cr√©er le fichier audio
    const audioPath = await createTTSAudio(answer, "fr");

    // Envoyer le fichier audio comme pi√®ce jointe
    const attachment = new AttachmentBuilder(audioPath, {
      name: "message_vocal.opus",
      description: answer,
    });

    await channel.send({
      files: [attachment],
      content: `üé§ **R√©ponse vocale:**\n${answer}`,
    });

    // Nettoyer le fichier temporaire
    setTimeout(() => {
      if (fs.existsSync(audioPath)) {
        fs.removeSync(audioPath);
      }
    }, 5000);
  } catch (error) {
    console.error("Erreur envoi message vocal:", error);
    channel.send("‚ùå Erreur lors de la g√©n√©ration du message vocal.");
  }
}

client.on("messageCreate", async (message) => {
  if (message.author.bot) return;

  // Commande pour rejoindre un salon vocal
  if (message.content.startsWith("!join")) {
    const voiceChannel = message.member?.voice.channel;
    if (!voiceChannel)
      return message.reply("üîä Rejoins d'abord un salon vocal !");
    
    await handleVoiceChannel(voiceChannel, message.guild.id, message.author.id);
    message.reply("‚úÖ Bot pr√™t √† √©couter et parler !");
    return;
  }

  // Commande pour quitter le salon vocal
  if (message.content.startsWith("!leave")) {
    const connection = getVoiceConnection(message.guild.id);
    if (connection) {
      connection.destroy();
      message.reply("üëã J'ai quitt√© le salon vocal.");
    } else {
      message.reply("‚ùå Je ne suis dans aucun salon vocal.");
    }
    return;
  }

  // Commande pour envoyer un message vocal dans le chat
  if (message.content.startsWith("!voice") || message.content.startsWith("!vocal")) {
    const text = message.content.slice(message.content.indexOf(" ") + 1).trim();
    if (!text) {
      return message.reply("‚ùå Utilise: `!voice [votre message]` ou `!vocal [votre message]`");
    }
    
    await sendVoiceMessage(message.channel, text, message.author.id);
    return;
  }

  // Commande pour voir la cam√©ra
  if (message.content.startsWith("!camera") || message.content.startsWith("!cam") || message.content.startsWith("!visio")) {
    const question = message.content.slice(message.content.indexOf(" ") + 1).trim();
    
    await message.reply("üì∑ Capture de la cam√©ra en cours...");
    
    try {
      const imagePath = await captureWebcam();
      
      if (!imagePath) {
        return message.reply("‚ùå Impossible de capturer la cam√©ra. V√©rifie que ta cam√©ra est connect√©e et autoris√©e.");
      }

      // Analyser l'image avec Gemini
      const description = await analyzeImageWithGemini(imagePath, question || null);
      
      // Envoyer l'image et la description
      const attachment = new AttachmentBuilder(imagePath, {
        name: "camera.jpg",
        description: "Capture de la cam√©ra",
      });

      await message.channel.send({
        files: [attachment],
        content: `üì∑ **Ce que je vois :**\n${description}`,
      });

      // Nettoyer le fichier temporaire
      setTimeout(() => {
        if (fs.existsSync(imagePath)) {
          fs.removeSync(imagePath);
        }
      }, 60000); // Garder 1 minute au cas o√π
    } catch (error) {
      console.error("Erreur capture cam√©ra:", error);
      let errorMsg = "‚ùå Erreur lors de la capture de la cam√©ra.";
      
      if (error.message && error.message.includes("imagesnap")) {
        errorMsg = error.message;
      } else if (error.message && error.message.includes("Command failed")) {
        errorMsg = "‚ùå imagesnap n'est pas install√©.\nüí° Pour installer sur macOS: `brew install imagesnap`\nüí° Alternative: Utilisez `!screen` pour capturer l'√©cran";
      } else {
        errorMsg += " V√©rifie que ta cam√©ra est disponible et autoris√©e.";
      }
      
      message.reply(errorMsg);
    }
    return;
  }

  // Commande pour voir l'√©cran
  if (message.content.startsWith("!screen") || message.content.startsWith("!ecran") || message.content.startsWith("!analyse")) {
    const question = message.content.slice(message.content.indexOf(" ") + 1).trim();
    
    await message.reply("üì∏ Capture de l'√©cran en cours...");
    
    try {
      const imagePath = await captureScreen();
      
      if (!imagePath) {
        return message.reply("‚ùå Impossible de capturer l'√©cran.");
      }

      // Analyser l'image avec Gemini
      const description = await analyzeImageWithGemini(imagePath, question || null);
      
      // Envoyer l'image et la description
      const attachment = new AttachmentBuilder(imagePath, {
        name: "screen.png",
        description: "Capture d'√©cran",
      });

      await message.channel.send({
        files: [attachment],
        content: `üñ•Ô∏è **Ce que je vois sur l'√©cran :**\n${description}`,
      });

      // Nettoyer le fichier temporaire
      setTimeout(() => {
        if (fs.existsSync(imagePath)) {
          fs.removeSync(imagePath);
        }
      }, 60000);
    } catch (error) {
      console.error("Erreur capture √©cran:", error);
      let errorMsg = "‚ùå Erreur lors de la capture de l'√©cran.";
      
      if (error.status === 429) {
        errorMsg = "‚ùå Trop de requ√™tes vers Gemini API. Attends quelques secondes et r√©essaye.";
      } else if (error.message) {
        errorMsg += ` ${error.message}`;
      }
      
      message.reply(errorMsg);
    }
    return;
  }

  // R√©pondre aux messages mentionnant le bot ou commen√ßant par "!"
  const mentioned = message.mentions.has(client.user);
  const isCommand = message.content.startsWith("!");
  
  if (mentioned || (isCommand && !message.content.startsWith("!join") && !message.content.startsWith("!leave") && !message.content.startsWith("!voice") && !message.content.startsWith("!vocal") && !message.content.startsWith("!camera") && !message.content.startsWith("!cam") && !message.content.startsWith("!visio") && !message.content.startsWith("!screen") && !message.content.startsWith("!ecran") && !message.content.startsWith("!analyse"))) {
    try {
      const userMessage = message.content.replace(`<@${client.user.id}>`, "").trim();
      const answer = await generateTextWithGemini(userMessage, message.author.id);
      await message.reply(answer);
    } catch (error) {
      console.error("Erreur r√©ponse texte:", error);
      message.reply("‚ùå D√©sol√©, une erreur s'est produite.");
    }
  }
});

client.login(process.env.DISCORD_TOKEN);
